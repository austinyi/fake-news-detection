{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIsEhVA0zTiY"
      },
      "source": [
        "# MLP with TF-IDF\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoFpHcYUsuRC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torch import Tensor\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f9z8gR_yYcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ab00ca-eadd-4e5c-ac17-d624e3b8241d"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2g1OxQtya34"
      },
      "source": [
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We use TF_IDF here. For the analysis with BOW and Bigram, you can use the same code by only changing the data reading part.\n",
        "\n",
        "e.g. train_TF_IDF.p -> train_BOW.p\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Or9uhDKKy_6L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHuCsqGfJC1x",
        "outputId": "e446a773-e0d8-4872-d7cd-c2166e107c71"
      },
      "source": [
        "# Load data\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('/train_TF_IDF.p', 'rb') as file:\n",
        "    X_train = pickle.load(file)\n",
        "    y_train = pickle.load(file)\n",
        "    wordlist_filtered = pickle.load(file)\n",
        "\n",
        "with open('/test_K1_TF_IDF.p', 'rb') as file:\n",
        "    X_test_K1 = pickle.load(file)\n",
        "    y_test_K1 = pickle.load(file)\n",
        "    wordlist_filtered = pickle.load(file)\n",
        "\n",
        "with open('/test_K2_TF_IDF.p', 'rb') as file:\n",
        "    X_test_K2 = pickle.load(file)\n",
        "    y_test_K2 = pickle.load(file)\n",
        "    wordlist_filtered = pickle.load(file)\n",
        "\n",
        "with open('/test_K3_TF_IDF.p', 'rb') as file:\n",
        "    X_test_K3 = pickle.load(file)\n",
        "    y_test_K3 = pickle.load(file)\n",
        "    wordlist_filtered = pickle.load(file)\n",
        "\n",
        "with open('/test_L_TF_IDF.p', 'rb') as file:\n",
        "    X_test_L = pickle.load(file)\n",
        "    y_test_L = pickle.load(file)\n",
        "    wordlist_filtered = pickle.load(file)\n",
        "\n",
        "# Include top 1000 frequent words only\n",
        "\n",
        "\n",
        "X_train = X_train.todense()\n",
        "print(X_train.shape)\n",
        "print(X_train)\n",
        "\n",
        "X_test = X_test_K1\n",
        "X_test = X_test.todense()\n",
        "print(X_test.shape)\n",
        "print(X_test)\n",
        "\n",
        "y_test = y_test_K1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26939, 1000)\n",
            "[[0.         0.         0.         ... 0.02843602 0.04265403 0.07582938]\n",
            " [0.         0.         0.         ... 0.02389078 0.03412969 0.0887372 ]\n",
            " [0.         0.         0.00326797 ... 0.05882353 0.06535948 0.08496732]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.06341463 0.02926829 0.10243902]\n",
            " [0.         0.         0.         ... 0.05555556 0.04166667 0.08333333]\n",
            " [0.         0.         0.         ... 0.04958678 0.07438017 0.04132231]]\n",
            "(17959, 1000)\n",
            "[[0.         0.         0.         ... 0.01812689 0.04229607 0.03927492]\n",
            " [0.         0.         0.         ... 0.02840909 0.04829545 0.05113636]\n",
            " [0.         0.00452489 0.         ... 0.05429864 0.04524887 0.04977376]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.03061224 0.05510204 0.10612245]\n",
            " [0.         0.         0.         ... 0.02439024 0.03658537 0.11890244]\n",
            " [0.         0.         0.         ... 0.02446483 0.05810398 0.0733945 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT9DcfMuaEnn"
      },
      "source": [
        "y_train = y_train.values\n",
        "y_test = y_test.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JTv_Y8FJCsO"
      },
      "source": [
        "## train data\n",
        "class TrainData(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "train_data = TrainData(torch.FloatTensor(X_train), \n",
        "                       torch.FloatTensor(y_train))\n",
        "\n",
        "## test data    \n",
        "class TestData(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "    \n",
        "\n",
        "test_data = TestData(torch.FloatTensor(X_test),\n",
        "                     torch.FloatTensor(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9dFL0sJCmS"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYoGRUBsccgu"
      },
      "source": [
        "class BinaryClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassification, self).__init__()\n",
        "        # Number of input features is 1000.\n",
        "        self.layer_1 = nn.Linear(1000, 64) \n",
        "        self.layer_2 = nn.Linear(64, 64)\n",
        "        self.layer_out = nn.Linear(64, 1) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = self.relu(self.layer_1(inputs))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(self.layer_2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWtpNckdco2b",
        "outputId": "6334bd50-4958-490d-8c30-61a6f70b0ea5"
      },
      "source": [
        "model = BinaryClassification()\n",
        "model.to(DEVICE)\n",
        "print(model)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BinaryClassification(\n",
            "  (layer_1): Linear(in_features=1000, out_features=64, bias=True)\n",
            "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IJH2ncocotl"
      },
      "source": [
        "def binary_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBMFnf4-YFYt"
      },
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "        \n",
        "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        train_accuracy += acc.item()\n",
        "    train_loss /= len(train_loader)\n",
        "    train_accuracy /=len(train_loader)\n",
        "    return train_loss, train_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FdY57YsdZ7E"
      },
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
        "            y_pred = model(X_batch)\n",
        "\n",
        "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_accuracy += acc.item()\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy /=len(test_loader)\n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d9ZLuxdcohb"
      },
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_accuracy = train(model, train_loader, optimizer)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print('[{}] Train Loss: {:.4f}, Train Accuracy: {:.2f}%'.format(\n",
        "      epoch, train_loss, train_accuracy))\n",
        "    print('[{}] Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur3pKjtZd5Gj",
        "outputId": "d05e5133-1391-4e92-e456-19d55a8284a4"
      },
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_accuracy = train(model, train_loader, optimizer)\n",
        "    print('[{}] Train Loss: {:.4f}, Train Accuracy: {:.2f}%'.format(\n",
        "      epoch, train_loss, train_accuracy))\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "print('[{}] Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Train Loss: 0.1278, Train Accuracy: 95.28%\n",
            "[2] Train Loss: 0.0809, Train Accuracy: 96.99%\n",
            "[3] Train Loss: 0.0664, Train Accuracy: 97.49%\n",
            "[4] Train Loss: 0.0562, Train Accuracy: 97.81%\n",
            "[5] Train Loss: 0.0446, Train Accuracy: 98.29%\n",
            "[6] Train Loss: 0.0415, Train Accuracy: 98.40%\n",
            "[7] Train Loss: 0.0326, Train Accuracy: 98.63%\n",
            "[8] Train Loss: 0.0288, Train Accuracy: 98.87%\n",
            "[9] Train Loss: 0.0236, Train Accuracy: 99.04%\n",
            "[10] Train Loss: 0.0220, Train Accuracy: 99.13%\n",
            "[11] Train Loss: 0.0204, Train Accuracy: 99.21%\n",
            "[12] Train Loss: 0.0263, Train Accuracy: 98.95%\n",
            "[13] Train Loss: 0.0194, Train Accuracy: 99.23%\n",
            "[14] Train Loss: 0.0163, Train Accuracy: 99.38%\n",
            "[15] Train Loss: 0.0148, Train Accuracy: 99.41%\n",
            "[16] Train Loss: 0.0137, Train Accuracy: 99.47%\n",
            "[17] Train Loss: 0.0106, Train Accuracy: 99.59%\n",
            "[18] Train Loss: 0.0121, Train Accuracy: 99.52%\n",
            "[19] Train Loss: 0.0104, Train Accuracy: 99.58%\n",
            "[20] Train Loss: 0.0102, Train Accuracy: 99.65%\n",
            "[21] Train Loss: 0.0092, Train Accuracy: 99.65%\n",
            "[22] Train Loss: 0.0109, Train Accuracy: 99.59%\n",
            "[23] Train Loss: 0.0104, Train Accuracy: 99.58%\n",
            "[24] Train Loss: 0.0072, Train Accuracy: 99.73%\n",
            "[25] Train Loss: 0.0069, Train Accuracy: 99.76%\n",
            "[26] Train Loss: 0.0071, Train Accuracy: 99.76%\n",
            "[27] Train Loss: 0.0090, Train Accuracy: 99.63%\n",
            "[28] Train Loss: 0.0056, Train Accuracy: 99.74%\n",
            "[29] Train Loss: 0.0080, Train Accuracy: 99.66%\n",
            "[30] Train Loss: 0.0092, Train Accuracy: 99.64%\n",
            "[30] Test Loss: 2.9399, Test Accuracy: 76.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FESvZ8bDvJs2",
        "outputId": "4c1dd496-0f43-4565-e313-e36c4db3d1dd"
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "print('[{}] Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30] Test Loss: 0.1490, Test Accuracy: 97.16%\n"
          ]
        }
      ]
    }
  ]
}